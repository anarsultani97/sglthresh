MLP results

1 - static 0.3

train
              precision    recall  f1-score   support

           0      0.333     0.239     0.278        88
           1      0.364     0.389     0.376        72
           2      0.383     0.788     0.516       104
           3      0.236     0.517     0.324        58
           4      0.187     0.328     0.238        61
           5      0.296     0.293     0.294        82

   micro avg      0.306     0.441     0.362       465
   macro avg      0.300     0.426     0.338       465
weighted avg      0.311     0.441     0.350       465
 samples avg      0.307     0.437     0.338       465

set acc: 0.054
dev
              precision    recall  f1-score   support

           0      0.500     0.452     0.475        31
           1      0.280     0.200     0.233        35
           2      0.531     0.938     0.678        64
           3      0.385     0.806     0.521        31
           4      0.420     0.618     0.500        34
           5      0.758     0.510     0.610        49

   micro avg      0.484     0.623     0.545       244
   macro avg      0.479     0.587     0.503       244
weighted avg      0.502     0.623     0.530       244
 samples avg      0.487     0.626     0.511       244

set acc: 0.138
test
              precision    recall  f1-score   support

           0      0.565     0.481     0.520        54
           1      0.259     0.119     0.163        59
           2      0.494     0.896     0.637        96
           3      0.440     0.814     0.571        59
           4      0.470     0.644     0.543        73
           5      0.642     0.586     0.613        58

   micro avg      0.487     0.622     0.546       399
   macro avg      0.478     0.590     0.508       399
weighted avg      0.478     0.622     0.521       399
 samples avg      0.472     0.624     0.510       399

set acc: 0.124

2 - numThresh

auto_thresholds 0.2370 0.2934 0.3022 0.3549 0.3127 0.2538 

auto_thresholds 0.2399 0.2419 0.4007 0.3575 0.3215 0.2524 
train
              precision    recall  f1-score   support

           0      0.336     0.500     0.402        88
           1      0.312     0.403     0.352        72
           2      0.383     0.788     0.516       104
           3      0.247     0.379     0.299        58
           4      0.204     0.311     0.247        61
           5      0.294     0.488     0.367        82

   micro avg      0.312     0.508     0.387       465
   macro avg      0.296     0.478     0.364       465
weighted avg      0.307     0.508     0.380       465
 samples avg      0.310     0.508     0.366       465

set acc: 0.038
dev
              precision    recall  f1-score   support

           0      0.444     0.774     0.565        31
           1      0.267     0.229     0.246        35
           2      0.531     0.938     0.678        64
           3      0.511     0.774     0.615        31
           4      0.487     0.559     0.521        34
           5      0.691     0.776     0.731        49

   micro avg      0.512     0.709     0.595       244
   macro avg      0.488     0.675     0.559       244
weighted avg      0.505     0.709     0.582       244
 samples avg      0.536     0.731     0.579       244

set acc: 0.146
test
              precision    recall  f1-score   support

           0      0.494     0.722     0.586        54
           1      0.243     0.153     0.188        59
           2      0.494     0.896     0.637        96
           3      0.500     0.678     0.576        59
           4      0.494     0.562     0.526        73
           5      0.575     0.862     0.690        58

   micro avg      0.491     0.664     0.564       399
   macro avg      0.467     0.645     0.534       399
weighted avg      0.470     0.664     0.542       399
 samples avg      0.481     0.674     0.533       399

set acc: 0.114
â€‹
3 - SGL with thresh learnable

auto_thresholds 0.2567 0.2466 0.3812 0.3710 0.3354 0.2399 
train
              precision    recall  f1-score   support

           0      0.345     0.432     0.384        88
           1      0.267     0.597     0.369        72
           2      0.386     0.683     0.493       104
           3      0.235     0.328     0.273        58
           4      0.233     0.279     0.254        61
           5      0.308     0.549     0.395        82

   micro avg      0.309     0.501     0.382       465
   macro avg      0.296     0.478     0.361       465
weighted avg      0.307     0.501     0.377       465
 samples avg      0.304     0.513     0.364       465

set acc: 0.034
dev
              precision    recall  f1-score   support

           0      0.442     0.613     0.514        31
           1      0.333     0.714     0.455        35
           2      0.582     0.891     0.704        64
           3      0.525     0.677     0.592        31
           4      0.516     0.471     0.492        34
           5      0.621     0.837     0.713        49

   micro avg      0.507     0.734     0.600       244
   macro avg      0.503     0.700     0.578       244
weighted avg      0.520     0.734     0.602       244
 samples avg      0.513     0.759     0.576       244

set acc: 0.100
test
              precision    recall  f1-score   support

           0      0.514     0.667     0.581        54
           1      0.294     0.542     0.381        59
           2      0.548     0.833     0.661        96
           3      0.520     0.661     0.582        59
           4      0.607     0.507     0.552        73
           5      0.543     0.879     0.671        58

   micro avg      0.495     0.689     0.577       399
   macro avg      0.504     0.682     0.571       399
weighted avg      0.512     0.689     0.579       399
 samples avg      0.475     0.700     0.539       399

set acc: 0.074


4 - SGL with thresh and sigma learnable

auto_thresholds 0.2399 0.2419 0.4007 0.3575 0.3215 0.2524 
train
              precision    recall  f1-score   support

           0      0.331     0.489     0.394        88
           1      0.263     0.611     0.368        72
           2      0.384     0.635     0.478       104
           3      0.250     0.379     0.301        58
           4      0.221     0.311     0.259        61
           5      0.294     0.488     0.367        82

   micro avg      0.300     0.503     0.376       465
   macro avg      0.291     0.485     0.361       465
weighted avg      0.301     0.503     0.375       465
 samples avg      0.297     0.511     0.359       465

set acc: 0.031
dev
              precision    recall  f1-score   support

           0      0.480     0.774     0.593        31
           1      0.338     0.771     0.470        35
           2      0.588     0.891     0.708        64
           3      0.511     0.742     0.605        31
           4      0.514     0.529     0.522        34
           5      0.667     0.776     0.717        49

   micro avg      0.514     0.766     0.615       244
   macro avg      0.516     0.747     0.602       244
weighted avg      0.534     0.766     0.622       244
 samples avg      0.524     0.786     0.593       244

set acc: 0.108
test
              precision    recall  f1-score   support

           0      0.494     0.722     0.586        54
           1      0.302     0.593     0.400        59
           2      0.572     0.823     0.675        96
           3      0.500     0.678     0.576        59
           4      0.542     0.534     0.538        73
           5      0.575     0.862     0.690        58

   micro avg      0.493     0.707     0.581       399
   macro avg      0.497     0.702     0.577       399
weighted avg      0.506     0.707     0.585       399
 samples avg      0.468     0.717     0.541       399

set acc: 0.059



